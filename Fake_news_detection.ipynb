{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badhanamitroy/FakeNewsDetector/blob/main/Fake_news_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUP_5MLQGvb6",
        "outputId": "51b7cfc1-1b55-42a3-a775-67c688893419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 1: Mount Google Drive\n",
        "# =============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to your custom datasets\n",
        "custom_fake_path = \"/content/drive/MyDrive/Colab Notebooks/FakeNews/Fake.csv\"\n",
        "custom_real_path = \"/content/drive/MyDrive/Colab Notebooks/RealNews/True.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7PiykyCG313"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# STEP 2: Import Libraries\n",
        "# =============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6OShUFQG_La",
        "outputId": "b976f1fa-90c3-461a-ec32-8b6a713c861c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Attempting to load: /content/drive/MyDrive/Colab Notebooks/FakeNews/Fake.csv\n",
            "Loaded 23481 rows. Columns: ['title', 'text', 'subject', 'date']\n",
            "\n",
            "Attempting to load: /content/drive/MyDrive/Colab Notebooks/RealNews/True.csv\n",
            "Loaded 21417 rows. Columns: ['title', 'text', 'subject', 'date']\n",
            "\n",
            "✓ Fake News Dataset: 23481 rows\n",
            "✓ Real News Dataset: 21417 rows\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 4: Load Custom Datasets\n",
        "# =============================\n",
        "def load_custom_dataset(path, true_label):\n",
        "    \"\"\"\n",
        "    Load custom CSV dataset and assign label based on the file.\n",
        "    \"\"\"\n",
        "    print(f\"\\nAttempting to load: {path}\")\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Error: File not found at {path}\")\n",
        "        return None\n",
        "    if not os.path.isfile(path):\n",
        "        print(f\"Error: Path is a directory, not a file: {path}\")\n",
        "        return None\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"Loaded {len(df)} rows. Columns: {df.columns.tolist()}\")\n",
        "\n",
        "    # Combine title + text → statement\n",
        "    statement_parts = []\n",
        "    if 'title' in df.columns:\n",
        "        statement_parts.append(df[\"title\"].fillna(\"\").astype(str))\n",
        "    if 'text' in df.columns:\n",
        "        statement_parts.append(df[\"text\"].fillna(\"\").astype(str))\n",
        "\n",
        "    if not statement_parts:\n",
        "        print(f\"Error: Could not find 'title' or 'text' columns\")\n",
        "        return None\n",
        "\n",
        "    # Concatenate with space separator\n",
        "    df[\"statement\"] = statement_parts[0]\n",
        "    for part in statement_parts[1:]:\n",
        "        df[\"statement\"] = df[\"statement\"] + \" \" + part\n",
        "\n",
        "    # Assign the label\n",
        "    df[\"label\"] = true_label\n",
        "    df[\"source\"] = \"fake_csv\" if true_label == \"fake\" else \"real_csv\"\n",
        "\n",
        "    # Keep only statement + label + source\n",
        "    df = df[[\"statement\", \"label\", \"source\"]].copy()\n",
        "\n",
        "    return df.dropna()\n",
        "\n",
        "# Load the datasets\n",
        "df_fake = load_custom_dataset(custom_fake_path, \"fake\")\n",
        "df_real = load_custom_dataset(custom_real_path, \"real\")\n",
        "\n",
        "if df_fake is None or df_real is None:\n",
        "    raise ValueError(\"Cannot proceed without custom datasets\")\n",
        "\n",
        "print(f\"\\n✓ Fake News Dataset: {len(df_fake)} rows\")\n",
        "print(f\"✓ Real News Dataset: {len(df_real)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlnxELgHS3n",
        "outputId": "514d43e3-5faf-468f-fe15-6ce57920308f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "COMBINED DATASET STATISTICS\n",
            "==================================================\n",
            "Total dataset size: 44898 rows\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "fake    23481\n",
            "real    21417\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label percentages:\n",
            "label\n",
            "fake    52.298543\n",
            "real    47.701457\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Source distribution:\n",
            "source\n",
            "fake_csv    23481\n",
            "real_csv    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 5: Merge All Datasets\n",
        "# =============================\n",
        "if USE_LIAR_DATASET and df_liar_all is not None:\n",
        "    df_liar_all[\"source\"] = \"liar\"\n",
        "    combined = pd.concat([df_liar_all, df_fake, df_real], ignore_index=True)\n",
        "else:\n",
        "    combined = pd.concat([df_fake, df_real], ignore_index=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMBINED DATASET STATISTICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total dataset size: {combined.shape[0]} rows\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(combined['label'].value_counts())\n",
        "print(f\"\\nLabel percentages:\")\n",
        "print(combined['label'].value_counts(normalize=True) * 100)\n",
        "print(f\"\\nSource distribution:\")\n",
        "print(combined['source'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_mWQwK2HZJu",
        "outputId": "ecd3da91-bb32-4499-f636-af4cdee91729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset size after cleaning: 44889 rows\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 6: Preprocess Text\n",
        "# =============================\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"www\\S+\", \"\", text)\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "combined[\"statement\"] = combined[\"statement\"].apply(clean_text)\n",
        "combined = combined[combined[\"statement\"].str.len() > 10]\n",
        "\n",
        "print(f\"\\nDataset size after cleaning: {combined.shape[0]} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZmDJf2oHmR_",
        "outputId": "06ebce96-a146-4bae-bbe0-57e78f4459d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set: 35911 rows\n",
            "Test set: 8978 rows\n",
            "Training label distribution:\n",
            "label\n",
            "fake    18777\n",
            "real    17134\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 7: Train/Test Split\n",
        "# =============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    combined[\"statement\"], combined[\"label\"],\n",
        "    test_size=0.2, stratify=combined[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {len(X_train)} rows\")\n",
        "print(f\"Test set: {len(X_test)} rows\")\n",
        "print(f\"Training label distribution:\\n{y_train.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXS91pdsHrzw",
        "outputId": "a87610cf-d0f0-4515-ce03-6b12c286be18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "TRAINING MODEL\n",
            "==================================================\n",
            "✓ Model training complete!\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 8: TF-IDF + Logistic Regression\n",
        "# =============================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRAINING MODEL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,3),  # Include trigrams for better context\n",
        "    min_df=2,  # Ignore terms that appear in fewer than 2 documents\n",
        "    max_df=0.95  # Ignore terms that appear in more than 95% of documents\n",
        ")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf  = vectorizer.transform(X_test)\n",
        "\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    C=1.0,  # Regularization parameter\n",
        "    class_weight='balanced'  # Handle class imbalance\n",
        ")\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"✓ Model training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z5e6H4HHxWG",
        "outputId": "b592c5d9-d95e-4164-bf27-5b50abdc1802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "MODEL EVALUATION\n",
            "==================================================\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake     0.9917    0.9887    0.9902      4695\n",
            "        real     0.9877    0.9909    0.9893      4283\n",
            "\n",
            "    accuracy                         0.9898      8978\n",
            "   macro avg     0.9897    0.9898    0.9897      8978\n",
            "weighted avg     0.9898    0.9898    0.9898      8978\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4642   53]\n",
            " [  39 4244]]\n",
            "\n",
            "[True Negatives: 4642, False Positives: 53]\n",
            "[False Negatives: 39, True Positives: 4244]\n",
            "\n",
            "✓ Overall Accuracy: 0.9898 (98.98%)\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 9: Evaluation\n",
        "# =============================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(f\"\\n[True Negatives: {cm[0][0]}, False Positives: {cm[0][1]}]\")\n",
        "print(f\"[False Negatives: {cm[1][0]}, True Positives: {cm[1][1]}]\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n✓ Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_H22P2uH6hK",
        "outputId": "b1193b5b-4ca1-4847-b72e-134f5dbe8980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "TOP PREDICTIVE FEATURES\n",
            "==================================================\n",
            "\n",
            "Top 20 words/phrases indicating FAKE news:\n",
            "  'video' (weight: -8.8628)\n",
            "  'via' (weight: -6.4218)\n",
            "  'this' (weight: -5.4639)\n",
            "  'is' (weight: -4.9503)\n",
            "  'hillary' (weight: -4.8526)\n",
            "  'just' (weight: -4.7428)\n",
            "  'president trump' (weight: -4.6221)\n",
            "  'that' (weight: -4.4794)\n",
            "  'gop' (weight: -4.1859)\n",
            "  'obama' (weight: -4.0987)\n",
            "  'image' (weight: -3.6995)\n",
            "  'mr' (weight: -3.6061)\n",
            "  'america' (weight: -3.5017)\n",
            "  'you' (weight: -3.4726)\n",
            "  'breaking' (weight: -3.3245)\n",
            "  'image via' (weight: -3.2364)\n",
            "  'watch' (weight: -3.0806)\n",
            "  'our' (weight: -3.0556)\n",
            "  'american' (weight: -2.9285)\n",
            "  'even' (weight: -2.7114)\n",
            "\n",
            "Top 20 words/phrases indicating REAL news:\n",
            "  'reuters' (weight: 18.1435)\n",
            "  'said' (weight: 15.7858)\n",
            "  'washington reuters' (weight: 7.1132)\n",
            "  'on' (weight: 6.4436)\n",
            "  'said on' (weight: 5.7021)\n",
            "  'reuters the' (weight: 4.7447)\n",
            "  'on wednesday' (weight: 4.6673)\n",
            "  'on tuesday' (weight: 4.4180)\n",
            "  'on thursday' (weight: 4.3009)\n",
            "  'on friday' (weight: 4.1342)\n",
            "  'us' (weight: 4.1024)\n",
            "  'republican' (weight: 4.0501)\n",
            "  'washington' (weight: 3.9802)\n",
            "  'in' (weight: 3.9299)\n",
            "  'reuters us' (weight: 3.8110)\n",
            "  'on monday' (weight: 3.8026)\n",
            "  'us president' (weight: 3.6129)\n",
            "  'president donald trump' (weight: 3.5671)\n",
            "  'president donald' (weight: 3.5348)\n",
            "  'edt' (weight: 3.5263)\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 10: Analyze Top Features\n",
        "# =============================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TOP PREDICTIVE FEATURES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Get indices of top features\n",
        "top_fake_indices = np.argsort(coefficients)[:20]\n",
        "top_real_indices = np.argsort(coefficients)[-20:]\n",
        "\n",
        "print(\"\\nTop 20 words/phrases indicating FAKE news:\")\n",
        "for idx in top_fake_indices:\n",
        "    print(f\"  '{feature_names[idx]}' (weight: {coefficients[idx]:.4f})\")\n",
        "\n",
        "print(\"\\nTop 20 words/phrases indicating REAL news:\")\n",
        "for idx in top_real_indices[::-1]:\n",
        "    print(f\"  '{feature_names[idx]}' (weight: {coefficients[idx]:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjoSEQ-tIAcc"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# STEP 11: Prediction Function\n",
        "# =============================\n",
        "def predict_news(news_text, show_details=True):\n",
        "    \"\"\"\n",
        "    Predict whether a news article is fake or real.\n",
        "    \"\"\"\n",
        "    cleaned = clean_text(news_text)\n",
        "\n",
        "    if len(cleaned) < 10:\n",
        "        return \"Error: Text too short\", 0.0\n",
        "\n",
        "    text_tfidf = vectorizer.transform([cleaned])\n",
        "    prediction = model.predict(text_tfidf)[0]\n",
        "    probabilities = model.predict_proba(text_tfidf)[0]\n",
        "\n",
        "    # probabilities[0] is for 'fake', probabilities[1] is for 'real'\n",
        "    fake_prob = probabilities[0] * 100\n",
        "    real_prob = probabilities[1] * 100\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"PREDICTION RESULT\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"Text preview: {news_text[:100]}...\")\n",
        "        print(f\"\\nPrediction: {prediction.upper()}\")\n",
        "        print(f\"Confidence scores:\")\n",
        "        print(f\"  - FAKE: {fake_prob:.2f}%\")\n",
        "        print(f\"  - REAL: {real_prob:.2f}%\")\n",
        "        print(f\"{'='*50}\\n\")\n",
        "\n",
        "    return prediction, max(fake_prob, real_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlDQTQ_gIFyZ",
        "outputId": "2f7fe960-9324-486c-ed6c-92d50a8eff5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "READY FOR PREDICTIONS\n",
            "==================================================\n",
            "Use: predict_news('your news text here')\n",
            "\n",
            "Testing with samples from your datasets:\n",
            "\n",
            "============================================================\n",
            "TEST 1: Sample from Fake.csv\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "PREDICTION RESULT\n",
            "==================================================\n",
            "Text preview:  Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing Donald Trump just co...\n",
            "\n",
            "Prediction: FAKE\n",
            "Confidence scores:\n",
            "  - FAKE: 98.32%\n",
            "  - REAL: 1.68%\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "TEST 2: Sample from True.csv\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "PREDICTION RESULT\n",
            "==================================================\n",
            "Text preview: As U.S. budget fight looms, Republicans flip their fiscal script WASHINGTON (Reuters) - The head of ...\n",
            "\n",
            "Prediction: REAL\n",
            "Confidence scores:\n",
            "  - FAKE: 1.03%\n",
            "  - REAL: 98.97%\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "Now try with your own text!\n",
            "==================================================\n",
            "\n",
            "Enter news text to analyze (or type 'exit' to quit):\n",
            "\n",
            "==================================================\n",
            "PREDICTION RESULT\n",
            "==================================================\n",
            "Text preview: SHOCKING: Doctors Reveal That Drinking Lemon Water Every Morning Cures Diabetes! Big Pharma Doesn't ...\n",
            "\n",
            "Prediction: FAKE\n",
            "Confidence scores:\n",
            "  - FAKE: 99.20%\n",
            "  - REAL: 0.80%\n",
            "==================================================\n",
            "\n",
            "\n",
            "Enter news text to analyze (or type 'exit' to quit):\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# STEP 12:\n",
        "Interactive Testing\n",
        "# =============================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"READY FOR PREDICTIONS\")\n",
        "print(\"=\"*50)\n",
        "print(\"Use: predict_news('your news text here')\\n\")\n",
        "\n",
        "# Test with actual samples from your datasets\n",
        "print(\"Testing with samples from your datasets:\\n\")\n",
        "\n",
        "if len(df_fake) > 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TEST 1: Sample from Fake.csv\")\n",
        "    print(\"=\" * 60)\n",
        "    fake_sample = df_fake.iloc[0]['statement']\n",
        "    predict_news(fake_sample[:500])  # Use first 500 chars\n",
        "\n",
        "if len(df_real) > 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TEST 2: Sample from True.csv\")\n",
        "    print(\"=\" * 60)\n",
        "    real_sample = df_real.iloc[0]['statement']\n",
        "    predict_news(real_sample[:500])  # Use first 500 chars\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Now try with your own text!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Interactive user input loop\n",
        "while True:\n",
        "    print(\"\\nEnter news text to analyze (or type 'exit' to quit):\")\n",
        "    user_input = input(\"> \")\n",
        "\n",
        "    if user_input.lower().strip() in ['exit', 'quit', 'q']:\n",
        "        print(\"Exiting prediction mode. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if len(user_input.strip()) < 10:\n",
        "        print(\"⚠️  Please enter a longer text (at least 10 characters)\")\n",
        "        continue\n",
        "\n",
        "    predict_news(user_input)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Lwo1bMKv4tUNaahixAiiOLDaLg8v7yAT",
      "authorship_tag": "ABX9TyO2AK5Q6NQF9FjB2D3lX3IS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}